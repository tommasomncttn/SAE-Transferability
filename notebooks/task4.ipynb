{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LVX-XSoCaj6D",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "2b3074ea-994e-4ff5-c873-d16260a9d23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sae-lens in /usr/local/lib/python3.10/dist-packages (3.21.1)\n",
            "Requirement already satisfied: transformer-lens in /usr/local/lib/python3.10/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: automated-interpretability<1.0.0,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.0.6)\n",
            "Requirement already satisfied: babe<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.0.7)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.17.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (2.21.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (3.9.2)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.1.7)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (3.8.1)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.19.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (5.24.1)\n",
            "Requirement already satisfied: plotly-express<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.4.1)\n",
            "Requirement already satisfied: pytest-profiling<2.0.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (1.7.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (1.0.1)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (6.0.2)\n",
            "Requirement already satisfied: pyzmq==26.0.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (26.0.0)\n",
            "Requirement already satisfied: safetensors<0.5.0,>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.4.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (4.44.2)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (4.12.2)\n",
            "Requirement already satisfied: zstandard<0.23.0,>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.22.0)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.34.2)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.14.1)\n",
            "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.0.3)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.8.0)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.0.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.2.34)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (2.1.4)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (13.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (4.66.5)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.18.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (0.24.7)\n",
            "Requirement already satisfied: blobfile<3.0.0,>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2.1.1)\n",
            "Requirement already satisfied: boostedblob<0.16.0,>=0.15.3 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.15.4)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.10.7)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.5.2)\n",
            "Requirement already satisfied: tiktoken<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.6.0)\n",
            "Requirement already satisfied: py2store in /usr/local/lib/python3.10/dist-packages (from babe<0.0.8,>=0.0.7->sae-lens) (0.1.20)\n",
            "Requirement already satisfied: graze in /usr/local/lib/python3.10/dist-packages (from babe<0.0.8,>=0.0.7->sae-lens) (0.1.24)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.17.1->sae-lens) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.10.5)\n",
            "Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens) (2.13.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.4.7)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline<0.2.0,>=0.1.6->sae-lens) (5.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (2024.9.11)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly<6.0.0,>=5.19.0->sae-lens) (9.0.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.14.3)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (1.13.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.5.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.16.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (7.4.4)\n",
            "Requirement already satisfied: gprof2dot in /usr/local/lib/python3.10/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (2024.6.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens) (2.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens) (3.1.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.1->sae-lens) (0.19.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.3->sae-lens) (1.5.4)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (3.20.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (2.14.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (71.0.4)\n",
            "Requirement already satisfied: pycryptodomex~=3.8 in /usr/local/lib/python3.10/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.20.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2.2.3)\n",
            "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (4.9.4)\n",
            "Requirement already satisfied: uvloop>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from boostedblob<0.16.0,>=0.15.3->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.20.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens) (4.0.11)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.17.1->sae-lens) (3.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.5.0)\n",
            "Requirement already satisfied: dol in /usr/local/lib/python3.10/dist-packages (from graze->babe<0.0.8,>=0.0.7->sae-lens) (0.2.76)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens) (2.1.5)\n",
            "Requirement already satisfied: config2py in /usr/local/lib/python3.10/dist-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (0.1.36)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (6.4.5)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens) (5.0.1)\n",
            "Requirement already satisfied: i2 in /usr/local/lib/python3.10/dist-packages (from config2py->py2store->babe<0.0.8,>=0.0.7->sae-lens) (0.1.33)\n"
          ]
        }
      ],
      "source": [
        "%pip install sae-lens transformer-lens torcheval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb4s_ZaaaYqZ",
        "outputId": "63933f2e-b63a-441f-e9bf-1779e6e7b2c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Standard imports\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import einops\n",
        "\n",
        "# import the LLM\n",
        "from sae_lens import SAE, HookedSAETransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "# For the most part I'll try to import functions and classes near where they are used\n",
        "# to make it clear where they come from.\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# utility to clear variables out of the memory & and clearing cuda cache\n",
        "import gc\n",
        "def clear_cache():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1-2VqKZaYqa"
      },
      "outputs": [],
      "source": [
        "# define the model to work with\n",
        "MODEL = 'MISTRAL' # GEMMA, GPT2\n",
        "\n",
        "if MODEL == 'GEMMA':\n",
        "    RELEASE = 'gemma-2b-res-jb'\n",
        "    BASE_MODEL = \"google/gemma-2b\"\n",
        "    FINETUNE_MODEL = 'shahdishank/gemma-2b-it-finetune-python-codes'\n",
        "    DATASET_NAME = \"ctigges/openwebtext-gemma-1024-cl\"\n",
        "    FINETUNE_PATH = None\n",
        "    BASE_TOKENIZER_NAME = BASE_MODEL\n",
        "\n",
        "    hook_part = 'post'\n",
        "    layer_num = 6\n",
        "elif MODEL == 'GPT2':\n",
        "    RELEASE = 'gpt2-small-res-jb'\n",
        "    BASE_MODEL = \"gpt2-small\"\n",
        "    FINETUNE_MODEL = 'pierreguillou/gpt2-small-portuguese'\n",
        "    FINETUNE_PATH = None\n",
        "    DATASET_NAME = \"Skylion007/openwebtext\"\n",
        "    BASE_TOKENIZER_NAME = BASE_MODEL\n",
        "\n",
        "    hook_part = 'pre'\n",
        "    layer_num = 6\n",
        "elif MODEL == 'MISTRAL':\n",
        "    RELEASE = 'mistral-7b-res-wg'\n",
        "    BASE_MODEL = \"mistral-7b\"\n",
        "    DATASET_NAME = \"monology/pile-uncopyrighted\"\n",
        "    BASE_TOKENIZER_NAME = 'mistralai/Mistral-7B-v0.1'\n",
        "\n",
        "    FINETUNE_MODEL = 'meta-math/MetaMath-Mistral-7B' #DeepMount00/Mistral-Ita-7b\n",
        "    FINETUNE_PATH = f'/content/drive/My Drive/Finetunes/MetaMath-Mistral-7B'\n",
        "\n",
        "    hook_part = 'pre'\n",
        "    layer_num = 8\n",
        "\n",
        "SAE_HOOK = f'blocks.{layer_num}.hook_resid_{hook_part}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F91e8uc7P4en"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "\n",
        "class Experiment(Enum):\n",
        "    SUBSTITUTION_LOSS = 'SubstitutionLoss'\n",
        "    L0_LOSS = 'L0_loss'\n",
        "    FEATURE_ACTS = 'FeatureActs'\n",
        "    FEATURE_DENSITY = 'FeatureDensity'\n",
        "\n",
        "TOTAL_BATCHES = {\n",
        "    Experiment.SUBSTITUTION_LOSS: 25,\n",
        "    Experiment.L0_LOSS: 50,\n",
        "    Experiment.FEATURE_ACTS: 25,\n",
        "    Experiment.FEATURE_DENSITY: 50\n",
        "}\n",
        "\n",
        "TOKENS_SAMPLE = {\n",
        "    Experiment.SUBSTITUTION_LOSS: [],\n",
        "    Experiment.L0_LOSS: [],\n",
        "    Experiment.FEATURE_ACTS: [],\n",
        "    Experiment.FEATURE_DENSITY: []\n",
        "}\n",
        "\n",
        "def get_batch_size(key: Experiment):\n",
        "    return TOTAL_BATCHES[key]\n",
        "\n",
        "def get_tokens_sample(key: Experiment):\n",
        "    return TOKENS_SAMPLE[key]\n",
        "\n",
        "def set_tokens_sample(key: Experiment, token_sample):\n",
        "    TOKENS_SAMPLE[key] = token_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jif4TBN7BL_K"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading finetune model"
      ],
      "metadata": {
        "id": "nBwWGuIZ4e6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "def adjust_state_dict(model, base_model_vocab_size):\n",
        "    \"\"\"Adjust the state_dict of the model to match the base model's vocab size.\"\"\"\n",
        "    state_dict = model.state_dict()\n",
        "\n",
        "    # Adjust the embedding matrix\n",
        "    if state_dict['model.embed_tokens.weight'].shape[0] > base_model_vocab_size:\n",
        "        state_dict['model.embed_tokens.weight'] = state_dict['model.embed_tokens.weight'][:base_model_vocab_size, :]\n",
        "\n",
        "    # Adjust the unembedding (lm_head) matrix\n",
        "    if state_dict['lm_head.weight'].shape[0] > base_model_vocab_size:\n",
        "        state_dict['lm_head.weight'] = state_dict['lm_head.weight'][:base_model_vocab_size, :]\n",
        "\n",
        "    return state_dict\n",
        "\n",
        "def load_hf_model(path, base_model=BASE_MODEL, device='cuda', dtype=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(path)\n",
        "\n",
        "    # Adjust the model's state dict to match the base model's vocab size\n",
        "    base_model_vocab_size = 32000  # Get base model vocab size\n",
        "    adjusted_state_dict = adjust_state_dict(model, base_model_vocab_size)\n",
        "\n",
        "    # Adjust model architecture to match the new vocab size\n",
        "    model.resize_token_embeddings(base_model_vocab_size)\n",
        "\n",
        "    # Load the adjusted state dict back into the model\n",
        "    model.load_state_dict(adjusted_state_dict, strict=False)\n",
        "\n",
        "    # Now load the fine-tuned model into the HookedSAETransformer\n",
        "    finetune_model = HookedSAETransformer.from_pretrained(\n",
        "        base_model, device=device, hf_model=model, dtype=dtype\n",
        "    )\n",
        "\n",
        "    del model  # offload the HF model as it's already wrapped into HookedSAETransformer (finetune_model)\n",
        "    clear_cache()\n",
        "\n",
        "    return tokenizer, finetune_model"
      ],
      "metadata": {
        "id": "M4N-rtoy4iHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1FcS0z1BL_L"
      },
      "source": [
        "#### Activations filtering utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoRMmhbhBL_L"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "import os\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "def load_outliers_config(filename='outlier_cfg.json'):\n",
        "    \"\"\"\n",
        "    This function checks if the script is running in Google Colab and loads the JSON file accordingly.\n",
        "    If running in Colab, it will mount Google Drive and load the file from there.\n",
        "    Otherwise, it will load the file from a local directory.\n",
        "    \"\"\"\n",
        "    if not IN_COLAB:\n",
        "        # If not in Colab, use local folder\n",
        "        # Assuming this is being run from the 'notebooks' folder\n",
        "        sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
        "\n",
        "        from saetuning.utils import OUTLIERS_CFG\n",
        "        return OUTLIERS_CFG\n",
        "\n",
        "    # If in Colab, mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Define the path to your JSON file in Google Drive\n",
        "    file_path = os.path.join('/content/drive/My Drive', filename)\n",
        "    print(f\"Loading JSON file from Google Drive: {file_path}\")\n",
        "\n",
        "    # Load the JSON data\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            data = json.load(file)\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI6JqtBVBL_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504b1961-5a24-4f28-c3d7-766e5c5d5959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading JSON file from Google Drive: /content/drive/My Drive/outlier_cfg.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'norm_scalar': {'google/gemma-2b': 0.31278620989943556,\n",
              "  'gpt2-small': 0.27139524668485193,\n",
              "  'mistral-7b': 14.178454680291779},\n",
              " 'threshhold_multiplier': {'google/gemma-2b': 2, 'gpt2-small': 2},\n",
              " 'base_threshhold': {'google/gemma-2b': 45.254833995939045,\n",
              "  'gpt2-small': 27.712812921102035},\n",
              " 'absolute_threshold': {'mistral-7b': 200}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "OUTLIERS_CFG = load_outliers_config()\n",
        "\n",
        "def get_norm_scalar(model_name):\n",
        "    return OUTLIERS_CFG.get(\"norm_scalar\", {}).get(model_name, None)\n",
        "\n",
        "def get_threshold_multiplier(model_name):\n",
        "    return OUTLIERS_CFG.get(\"threshhold_multiplier\", {}).get(model_name, None)\n",
        "\n",
        "def get_base_threshhold(model_name):\n",
        "    return OUTLIERS_CFG.get(\"base_threshhold\", {}).get(model_name, None)\n",
        "\n",
        "def get_absolute_threshhold(model_name):\n",
        "    return OUTLIERS_CFG.get(\"absolute_threshold\", {}).get(model_name, None)\n",
        "\n",
        "# Auxilary method for getting a mask of outlier activations\n",
        "def is_act_outlier(act_tensor, model_name):\n",
        "    \"\"\"\n",
        "    Expects act_tensor of shape [*, D_MODEL]\n",
        "\n",
        "    Returns a boolean tensor of shape [*], where for each batch position we report whether the corresponding activation\n",
        "    exceeds the outlier threshold that is defined as\n",
        "\n",
        "    threshold = threshold_multiplier * base_threshold, where\n",
        "    base_threshold = sqrt(D_MODEL)\n",
        "\n",
        "    Important! This threshold value is in the normalized scale, i.e. is meant to be used for activations that are scaled\n",
        "    in such a way, that their average norm is equal to sqrt(D_MODEL). To do this normalization, we multiple by norm_scalar\n",
        "    of the corresponding model.\n",
        "\n",
        "    Check this blog-post for more details: https://www.lesswrong.com/posts/fmwk6qxrpW8d4jvbd/saes-usually-transfer-between-base-and-chat-models\n",
        "    \"\"\"\n",
        "    norm_scalar = get_norm_scalar(model_name)\n",
        "    threshold_multiplier = get_threshold_multiplier(model_name)\n",
        "    base_threshold = get_base_threshhold(model_name)\n",
        "    absolute_threshhold = get_absolute_threshhold(model_name)\n",
        "\n",
        "    if absolute_threshhold:\n",
        "        threshold = norm_scalar * absolute_threshhold\n",
        "    else:\n",
        "        threshold = threshold_multiplier * base_threshold\n",
        "\n",
        "    scaled_act = norm_scalar * act_tensor\n",
        "    scaled_act_norms = torch.norm(scaled_act, dim=-1)\n",
        "\n",
        "    return scaled_act_norms > threshold\n",
        "\n",
        "OUTLIERS_CFG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01fn9LiFBL_M"
      },
      "outputs": [],
      "source": [
        "def filter_activations(acts, model_name=BASE_MODEL, return_mask=False):\n",
        "    \"\"\"\n",
        "    Filters out activations based on outlier norms and returns the filtered activations.\n",
        "\n",
        "    Args:\n",
        "        acts (torch.Tensor): A tensor of activations with shape [BATCH, SEQ, D_MODEL].\n",
        "        model_name (str): The name of the model used to determine the threshold for filtering out outlier activations.\n",
        "        return_mask (bool): If True, returns the 2D boolean mask indicating which activations were retained. The mask has shape [BATCH, SEQ].\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor of filtered activations with shape [N_VALID_ACTIVATIONS, D_MODEL], where N_VALID_ACTIVATIONS <= BATCH * SEQ.\n",
        "        torch.Tensor (optional): A 2D boolean tensor of shape [BATCH, SEQ] representing the filtering mask, indicating whether each activation was retained (True) or filtered out (False).\n",
        "\n",
        "    Notes:\n",
        "        - The function removes activations identified as outliers by `is_act_outlier`. The activations that pass the filter are flattened into a tensor of shape [N_VALID_ACTIVATIONS, D_MODEL].\n",
        "        - If `return_mask=True`, the function also returns a 2D boolean mask corresponding to the [BATCH, SEQ] dimensions of the original activations. This mask can be useful for tracking which activations were kept.\n",
        "        - The returned filtered activations are flattened across both batch and sequence dimensions. If reshaping back to a sequence or batch structure is required, you will need to do this outside the function based on the original mask.\n",
        "    \"\"\"\n",
        "    # Get the outlier mask\n",
        "    is_outlier_mask = is_act_outlier(acts, model_name)  # [BATCH, SEQ]\n",
        "\n",
        "    # Expand the mask to match the last dimension (D_MODEL) for correct filtering\n",
        "    expanded_mask = is_outlier_mask.unsqueeze(-1).expand_as(acts)  # [BATCH, SEQ, D_MODEL]\n",
        "\n",
        "    # Apply the mask and filter out the outlier activations\n",
        "    filtered_acts = acts[~expanded_mask].reshape(-1, acts.shape[-1])  # Flatten only the valid activations, retaining D_MODEL\n",
        "\n",
        "    if return_mask:\n",
        "        # Return the 2D mask corresponding to the original [BATCH, SEQ] shape\n",
        "        filter_mask = ~is_outlier_mask  # Keep it as 2D: [BATCH, SEQ]\n",
        "        return filtered_acts, filter_mask\n",
        "    else:\n",
        "        return filtered_acts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MVm963cBL_M"
      },
      "source": [
        "#### Score functions definition (copy from saetuning/utils.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJYK_EofaYqb"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from enum import Enum\n",
        "import numpy as np\n",
        "from scipy.stats import gamma\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from the .env file\n",
        "load_dotenv()\n",
        "\n",
        "#### Quantitave SAE evaluation ####\n",
        "def L0_loss(x, threshold=1e-8):\n",
        "    \"\"\"\n",
        "    Expects a tensor x of shape [N_TOKENS, N_SAE].\n",
        "\n",
        "    Returns a scalar representing the mean value of activated features (i.e. values across the N_SAE dimensions bigger than\n",
        "    the threshhold), a.k.a. L0 loss.\n",
        "    \"\"\"\n",
        "    return (x > threshold).float().sum(-1).mean()\n",
        "\n",
        "def get_substitution_loss(tokens, model, sae, sae_layer, reconstruction_metric=None):\n",
        "    '''\n",
        "    Expects a tensor of input tokens of shape [N_BATCHES, N_CONTEXT].\n",
        "\n",
        "    Returns two losses:\n",
        "    1. Clean loss - loss of the normal forward pass of the model at the input tokens.\n",
        "    2. Substitution loss - loss when substituting SAE reconstructions of the residual stream at the SAE layer of the model.\n",
        "    '''\n",
        "    # Run the model with cache to get the original activations and clean loss\n",
        "    loss_clean, cache = model.run_with_cache(tokens, names_filter=[sae_layer], return_type=\"loss\")\n",
        "\n",
        "    # Fetch and detach the original activations\n",
        "    original_activations = cache[sae_layer]\n",
        "\n",
        "    # Apply activation filtering\n",
        "    activations_filtered, filter_mask = filter_activations(original_activations, return_mask=True)\n",
        "    # Shape of activations_filtered is now [valid_activations, d_model]\n",
        "\n",
        "    # Filter the tokens using the same mask\n",
        "    tokens_filtered = tokens[filter_mask].reshape(activations_filtered.shape[0]) # shape [valid_activations]\n",
        "\n",
        "    # Get the SAE reconstructed activations\n",
        "    post_reconstructed = sae.forward(activations_filtered) # shape [valid_activations, d_model]\n",
        "\n",
        "    # Update the reconstruction quality metric, if provided\n",
        "    if reconstruction_metric:\n",
        "        reconstruction_metric.update(post_reconstructed.flatten().float(), activations_filtered.flatten().float())\n",
        "\n",
        "    # Free unused variables early to save memory\n",
        "    del original_activations, activations_filtered, cache\n",
        "    clear_cache()\n",
        "\n",
        "    # Hook function to substitute activations with SAE reconstructions\n",
        "    def hook_function(activations, hook, new_activations):\n",
        "        activations.copy_(new_activations)  # Perform in-place substitution of activations\n",
        "        return activations\n",
        "\n",
        "    # Run the model again with hooks to substitute activations at the SAE layer\n",
        "    loss_reconstructed = model.run_with_hooks(\n",
        "        tokens_filtered,\n",
        "        return_type=\"loss\",\n",
        "        fwd_hooks=[(sae_layer, partial(hook_function, new_activations=post_reconstructed))]\n",
        "    )\n",
        "\n",
        "    # Clean up the reconstructed activations and clear memory\n",
        "    del post_reconstructed\n",
        "    clear_cache()\n",
        "\n",
        "    return loss_clean, loss_reconstructed\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "from functools import partial\n",
        "\n",
        "def plot_log10_hist(y_data, y_value, num_bins=100, first_bin_name = 'First bin value',\n",
        "                    y_scalar=1.5, y_scale_bin=-2, log_epsilon=1e-10):\n",
        "    \"\"\"\n",
        "    Computes the histogram using PyTorch and plots the feature density diagram with log-10 scale using Plotly.\n",
        "    Y-axis is clipped to the value of the second-largest bin to prevent suppression of smaller values.\n",
        "    \"\"\"\n",
        "    # Flatten the tensor\n",
        "    y_data_flat = torch.flatten(y_data)\n",
        "\n",
        "    # Compute the logarithmic transformation using PyTorch\n",
        "    log_y_data_flat = torch.log10(torch.abs(y_data_flat) + log_epsilon).detach().cpu()\n",
        "\n",
        "    # Compute histogram using PyTorch\n",
        "    hist_min = torch.min(log_y_data_flat).item()\n",
        "    hist_max = torch.max(log_y_data_flat).item()\n",
        "    hist_range = hist_max - hist_min\n",
        "    bin_edges = torch.linspace(hist_min, hist_max, num_bins + 1)\n",
        "    hist_counts, _ = torch.histogram(log_y_data_flat, bins=bin_edges)\n",
        "\n",
        "    # Convert data to NumPy for Plotly\n",
        "    bin_edges_np = bin_edges.detach().cpu().numpy()\n",
        "    hist_counts_np = hist_counts.detach().cpu().numpy()\n",
        "\n",
        "    # Find the largest and second-largest bin values\n",
        "    first_bin_value = hist_counts_np[0]\n",
        "    scale_bin_value = sorted(hist_counts_np)[y_scale_bin]  # Get the second largest bin value (by default)\n",
        "\n",
        "    # Prepare the Plotly plot\n",
        "    fig = go.Figure(\n",
        "        data=[go.Bar(\n",
        "            x=bin_edges_np[:-1],  # Exclude the last bin edge\n",
        "            y=hist_counts_np,\n",
        "            width=hist_range / num_bins,\n",
        "        )]\n",
        "    )\n",
        "\n",
        "    # Update the layout for the plot, clipping the y-axis at the second largest bin value\n",
        "    fig.update_layout(\n",
        "        title=f\"SAE Features {y_value} histogram ({first_bin_name}: {first_bin_value:.2e})\",\n",
        "        xaxis_title=f\"Log10 of {y_value}\",\n",
        "        yaxis_title=\"Density\",\n",
        "        yaxis_range=[0, scale_bin_value * y_scalar],  # Clipping to the second-largest value by default\n",
        "        bargap=0.2,\n",
        "        bargroupgap=0.1,\n",
        "    )\n",
        "\n",
        "    # Add an annotation to display the value of the first bin\n",
        "    fig.add_annotation(\n",
        "        text=f\"{first_bin_name}: {first_bin_value:.2e}\",\n",
        "        xref=\"paper\", yref=\"paper\",\n",
        "        x=0.95, y=0.95,\n",
        "        showarrow=False,\n",
        "        font=dict(size=12, color=\"red\"),\n",
        "        bgcolor=\"white\",\n",
        "        bordercolor=\"black\",\n",
        "        borderwidth=1\n",
        "    )\n",
        "\n",
        "    # Show the plot\n",
        "    fig.show()\n",
        "\n",
        "class FeatureDensityPlotter:\n",
        "    def __init__(self, n_features, n_tokens, activation_threshold=1e-10, num_bins=100):\n",
        "        self.num_bins = num_bins\n",
        "        self.activation_threshold = activation_threshold\n",
        "\n",
        "        self.n_tokens = n_tokens\n",
        "        self.n_features = n_features\n",
        "\n",
        "        # Initialize a tensor of feature densities for all features,\n",
        "        # where feature density is defined as the fraction of tokens on which the feature has a nonzero value.\n",
        "        self.feature_densities = torch.zeros(n_features, dtype=torch.float32)\n",
        "\n",
        "    def update(self, feature_acts):\n",
        "        \"\"\"\n",
        "        Expects a tensor feature_acts of shape [N_TOKENS, N_FEATURES].\n",
        "\n",
        "        Updates the feature_densities buffer:\n",
        "        1. For each feature, count the number of tokens that the feature activated on (i.e. had an activation greater than the activation_threshold)\n",
        "        2. Add this count at the feature's position in the feature_densities tensor, divided by the total number of tokens (to compute the fraction)\n",
        "        \"\"\"\n",
        "\n",
        "        activating_tokens_count = (feature_acts > self.activation_threshold).float().sum(0)\n",
        "        self.feature_densities += activating_tokens_count / self.n_tokens\n",
        "\n",
        "    def plot(self, num_bins=100, y_scalar=1.5, y_scale_bin=-2, log_epsilon=1e-10):\n",
        "        plot_log10_hist(self.feature_densities, 'Density', num_bins=num_bins, first_bin_name='Dead features density',\n",
        "                        y_scalar=y_scalar, y_scale_bin=y_scale_bin, log_epsilon=log_epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABlYQE9JaYqb"
      },
      "source": [
        "### Task 4.1 Pretrained case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8oRMG-qaYqb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "ee45f96a5b174a75b68c405b6bafb9b5",
            "9d4374a927134e37912e081df0d1c025",
            "3cb9a007321c4894bb7ac46c8f1c35aa",
            "706c40f521824b4ebb2fdf2b45633490",
            "159e2699d2bb44f2a9a3cf9c3af780a6",
            "ac153d870cd9471494ebb7bd9699448d",
            "7763a6df19e3407faf6d300c563cdfa2",
            "0692f5a3c17f4940b454f53ae7838bc8",
            "7454f1750351443c84b2c8bd137d0527",
            "5bdccb792aa542a28622c3a7df70b3e5",
            "515e503c959045f280bee545711ceb0a"
          ]
        },
        "outputId": "283cd5d3-28a3-42a4-84e7-19ef7815ccb4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee45f96a5b174a75b68c405b6bafb9b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
            "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model mistral-7b into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "base_model = HookedSAETransformer.from_pretrained(BASE_MODEL, device=device, dtype=torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbjpczwWaYqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370b0602-033f-482c-8bfb-c2485cc06239"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'d_in': 4096,\n",
              " 'd_sae': 65536,\n",
              " 'dtype': 'float32',\n",
              " 'device': 'cuda',\n",
              " 'model_name': 'mistral-7b',\n",
              " 'hook_name': 'blocks.8.hook_resid_pre',\n",
              " 'hook_layer': 8,\n",
              " 'hook_head_index': None,\n",
              " 'activation_fn_str': 'relu',\n",
              " 'apply_b_dec_to_input': False,\n",
              " 'finetuning_scaling_factor': False,\n",
              " 'sae_lens_training_version': None,\n",
              " 'prepend_bos': False,\n",
              " 'dataset_path': 'monology/pile-uncopyrighted',\n",
              " 'context_size': 256,\n",
              " 'normalize_activations': 'constant_norm_rescale',\n",
              " 'dataset_trust_remote_code': True,\n",
              " 'architecture': 'standard',\n",
              " 'neuronpedia': None}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# import the required libraries\n",
        "from sae_lens import SAE\n",
        "\n",
        "sae_id = f'blocks.{layer_num}.hook_resid_{hook_part}'\n",
        "\n",
        "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
        "                            release = RELEASE,\n",
        "                            sae_id = sae_id,\n",
        "                            device = device\n",
        ")\n",
        "cfg_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIFp_EXJaYqc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6a26855-12bd-4704-959f-f300162fba0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'relu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# this must be checked for the forward method of sae.encode_xxx\n",
        "cfg_dict[\"activation_fn_str\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp9ACCQBaYqc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "f565615765d147789c678363e4b9b0dd",
            "5cd1a88e41f341af90d503bcc5dacabc",
            "a449e385fc0a4c50948aa90407253b57",
            "a51dca60ad0d48f9bb8adb252c664496",
            "f86bacf36e12413dba2a34fda650a234",
            "9fd5b206998540979d2796f538839ccd",
            "216670d6bcd24e03bdb25026dd4dbdef",
            "b266cab1b4b7412fabb1dc8ee2b0461f",
            "d223c86303a64cb4a495d4623802c8be",
            "830c8e2538d0443bbf80ad25b02a6069",
            "b52109a7755a46689ef1479915974a92"
          ]
        },
        "outputId": "fc7e08c3-c9e3-42ca-ac28-c9eb69caebe0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f565615765d147789c678363e4b9b0dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1280)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from sae_lens import ActivationsStore\n",
        "batch_size_prompts = 5\n",
        "\n",
        "# a convenient way to instantiate an activation store is to use the from_sae method\n",
        "activation_store = ActivationsStore.from_sae(\n",
        "    model=base_model,\n",
        "    sae=sae,\n",
        "    streaming=True,\n",
        "    # fairly conservative parameters here so can use same for larger\n",
        "    # models without running out of memory.\n",
        "    store_batch_size_prompts=batch_size_prompts,\n",
        "    train_batch_size_tokens=4096,\n",
        "    n_batches_in_buffer=32,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "batch_size_tokens = activation_store.context_size * batch_size_prompts\n",
        "\n",
        "batch_size_prompts, batch_size_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpu0bs7laYqc"
      },
      "source": [
        "#### 4.1.1 L0 loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5b0sdnAaYqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327c2f4d-940e-4059-a7dc-1c4504ba9051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [00:11<00:00,  4.19it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "all_L0 = []\n",
        "\n",
        "total_batches = get_batch_size(Experiment.L0_LOSS)\n",
        "all_tokens_L0 = get_tokens_sample(Experiment.L0_LOSS)\n",
        "\n",
        "for k in tqdm(range(total_batches)):\n",
        "    # Get a batch of tokens from the dataset\n",
        "    tokens = activation_store.get_batch_tokens()  # [N_BATCH, N_CONTEXT]\n",
        "\n",
        "    # Store tokens for later reuse\n",
        "    all_tokens_L0.append(tokens)\n",
        "\n",
        "    # Run the model and store the activations\n",
        "    _, cache = base_model.run_with_cache(tokens, stop_at_layer=layer_num + 1, \\\n",
        "                                         names_filter=[sae_id])  # [N_BATCH, N_CONTEXT, D_MODEL]\n",
        "\n",
        "    # Get the activations from the cache at the sae_id\n",
        "    activations_original = cache[sae_id]\n",
        "    # activations_filtered = filter_activations(activations_original)\n",
        "\n",
        "    # Encode the activations with the SAE\n",
        "    feature_activations = sae.encode_standard(activations_original) # the result of the encode method of the sae on the \"sae_id\" activations (a specific activation tensor of the LLM)\n",
        "    # feature_activations.to('cpu')\n",
        "\n",
        "    # Store the encoded activations\n",
        "    all_L0.append(L0_loss(feature_activations))\n",
        "\n",
        "    # Explicitly free up memory by deleting the cache and emptying the CUDA cache\n",
        "    del cache\n",
        "    del activations_original\n",
        "    del feature_activations\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Concatenate all tokens into a single tensor for reuse\n",
        "set_tokens_sample(Experiment.L0_LOSS, torch.cat(all_tokens_L0))  # [TOTAL_BATCHES * N_BATCH, N_CONTEXT]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipq3dCzUaYqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "856ad734-41d4-452f-aa2b-9600bdbb194d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(85.3981)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "torch.tensor(all_L0).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqZCKBJOaYqc"
      },
      "source": [
        "#### 4.1.2 Substitution Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4FMPdbmaYqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca3a9aa-4417-4328-b39f-c3ab4dbd8cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:42<00:00,  1.68s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from torcheval.metrics import R2Score\n",
        "sae_reconstruction_metric = R2Score().to(device)\n",
        "\n",
        "all_SL_clean = []\n",
        "all_SL_reconstructed = []\n",
        "\n",
        "total_batches = get_batch_size(Experiment.SUBSTITUTION_LOSS)\n",
        "all_tokens_SL = get_tokens_sample(Experiment.SUBSTITUTION_LOSS)\n",
        "\n",
        "for k in tqdm(range(total_batches)):\n",
        "    # Get a batch of tokens from the dataset\n",
        "    tokens = activation_store.get_batch_tokens()  # [N_BATCH, N_CONTEXT]\n",
        "    # Store tokens for later reuse\n",
        "    all_tokens_SL.append(tokens)\n",
        "\n",
        "    # Store loss\n",
        "    clean_loss, reconstructed_loss = get_substitution_loss(tokens, base_model, sae, sae_id, sae_reconstruction_metric)\n",
        "\n",
        "    all_SL_clean.append(clean_loss)\n",
        "    all_SL_reconstructed.append(reconstructed_loss)\n",
        "\n",
        "# Concatenate all tokens into a single tensor for reuse\n",
        "set_tokens_sample(Experiment.SUBSTITUTION_LOSS, torch.cat(all_tokens_SL))  # [TOTAL_BATCHES * N_BATCH, N_CONTEXT]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQZzgnxwaYqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb46c0b4-f564-498a-9924-f3a75588cfdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean vs substitution loss:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.7880859375, 2.4296875)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "print('Clean vs substitution loss:')\n",
        "torch.tensor(all_SL_clean).mean().item(), torch.tensor(all_SL_reconstructed).mean().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn7y8XQcG16I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ced9af6-160d-4221-9324-ed4126530a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Varience explained by SAE: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6823176145553589"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "print('Varience explained by SAE: ')\n",
        "sae_reconstruction_metric.compute().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiFDZeZhUcp4"
      },
      "source": [
        "#### 4.1.3 Feature activations histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2OlSXpsUcp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a7df73-5706-4f00-dec2-0b548823f12f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:11<00:00,  2.19it/s]\n"
          ]
        }
      ],
      "source": [
        "all_feature_acts = []\n",
        "\n",
        "total_batches = get_batch_size(Experiment.FEATURE_ACTS)\n",
        "all_histogram_tokens = get_tokens_sample(Experiment.FEATURE_ACTS)\n",
        "\n",
        "for k in tqdm(range(total_batches)):\n",
        "    # Get a batch of tokens from the dataset\n",
        "    tokens = activation_store.get_batch_tokens()  # [N_BATCH, N_CONTEXT]\n",
        "    all_histogram_tokens.append(tokens)\n",
        "\n",
        "    # Run the model and store the activations\n",
        "    _, cache = base_model.run_with_cache(tokens, stop_at_layer=layer_num + 1, \\\n",
        "                                         names_filter=[sae_id])  # [N_BATCH, N_CONTEXT, D_MODEL]\n",
        "\n",
        "    # Get the activations from the cache at the sae_id\n",
        "    activations_original = cache[sae_id] # [N_BATCH, N_CONTEXT, D_SAE]\n",
        "    # activations_filtered = filter_activations(activations_original)\n",
        "\n",
        "    # Encode the activations with the SAE\n",
        "    feature_activations = sae.encode_standard(activations_original) # the result of the encode method of the sae on the \"sae_id\" activations (a specific activation tensor of the LLM)\n",
        "    feature_activations = feature_activations.to('cpu')\n",
        "\n",
        "    # Store the encoded activations\n",
        "    all_feature_acts.append(feature_activations)\n",
        "\n",
        "    # Explicitly free up memory by deleting the cache and emptying the CUDA cache\n",
        "    del cache\n",
        "    del activations_original\n",
        "    del feature_activations\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "set_tokens_sample(Experiment.FEATURE_ACTS, torch.cat(all_histogram_tokens))  # [TOTAL_BATCHES * N_BATCH, N_CONTEXT]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8SY3gnYUcp5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c0f64467-faef-49cb-f94d-c9404afa6c19"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"decc33e6-e996-4e7a-8f49-c192ddbe3bdc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"decc33e6-e996-4e7a-8f49-c192ddbe3bdc\")) {                    Plotly.newPlot(                        \"decc33e6-e996-4e7a-8f49-c192ddbe3bdc\",                        [{\"width\":0.11829367399215698,\"x\":[-10.0,-9.881706,-9.763412,-9.645119,-9.526825,-9.408531,-9.290238,-9.171945,-9.053651,-8.935357,-8.817063,-8.69877,-8.580476,-8.462182,-8.343888,-8.2255945,-8.107302,-7.9890075,-7.8707137,-7.7524204,-7.6341267,-7.515833,-7.397539,-7.2792454,-7.1609516,-7.0426583,-6.9243646,-6.806071,-6.687777,-6.5694833,-6.45119,-6.332896,-6.2146025,-6.0963087,-5.978015,-5.8597217,-5.741428,-5.623134,-5.5048404,-5.3865466,-5.2682533,-5.1499596,-5.031666,-4.913372,-4.7950783,-4.6767845,-4.558491,-4.4401975,-4.3219037,-4.20361,-4.085316,-3.9670227,-3.848729,-3.7304351,-3.6121416,-3.4938478,-3.375554,-3.2572606,-3.1389668,-3.0206733,-2.9023795,-2.7840858,-2.6657922,-2.5474985,-2.429205,-2.3109112,-2.1926174,-2.074324,-1.9560301,-1.8377365,-1.7194428,-1.6011491,-1.4828554,-1.3645618,-1.246268,-1.1279744,-1.0096807,-0.8913871,-0.7730934,-0.6547997,-0.53650606,-0.41821238,-0.2999187,-0.18162504,-0.063331366,0.054962307,0.17325598,0.29154965,0.40984333,0.52813697,0.6464307,0.7647244,0.883018,1.0013117,1.1196053,1.2378991,1.3561927,1.4744864,1.5927801,1.7110738],\"y\":[100663300.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,2.0,5.0,9.0,6.0,5.0,16.0,13.0,20.0,24.0,19.0,58.0,50.0,67.0,96.0,142.0,180.0,250.0,292.0,422.0,514.0,701.0,935.0,1208.0,1617.0,2096.0,2584.0,3409.0,4510.0,5797.0,7272.0,9298.0,11716.0,14404.0,17769.0,21551.0,26253.0,31612.0,37455.0,45580.0,56095.0,68244.0,84089.0,101767.0,120863.0,142538.0,163170.0,182143.0,199768.0,210959.0,214151.0,204645.0,184345.0,153755.0,117364.0,82531.0,54213.0,34293.0,21499.0,11448.0,5140.0,1559.0,239.0,223.0],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis\":{\"title\":{\"text\":\"Density\"},\"range\":[0,321226.5]},\"title\":{\"text\":\"SAE Features activations histogram (First bin value: 1.01e+08)\"},\"xaxis\":{\"title\":{\"text\":\"Log10 of activations\"}},\"bargap\":0.2,\"bargroupgap\":0.1,\"annotations\":[{\"bgcolor\":\"white\",\"bordercolor\":\"black\",\"borderwidth\":1,\"font\":{\"color\":\"red\",\"size\":12},\"showarrow\":false,\"text\":\"First bin value: 1.01e+08\",\"x\":0.95,\"xref\":\"paper\",\"y\":0.95,\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('decc33e6-e996-4e7a-8f49-c192ddbe3bdc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "all_feature_acts = torch.cat(all_feature_acts)\n",
        "plot_log10_hist(all_feature_acts, 'activations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l2QKm5cUcp5"
      },
      "outputs": [],
      "source": [
        "del all_feature_acts\n",
        "clear_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e8hNp3QwbSG"
      },
      "source": [
        "#### 4.1.4 Feature density histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fN-lTqMwbSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a193549-aaca-478b-ec1d-741d7857ca4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [00:29<00:00,  1.72it/s]\n"
          ]
        }
      ],
      "source": [
        "all_histogram_tokens = get_tokens_sample(Experiment.FEATURE_DENSITY)\n",
        "total_batches = get_batch_size(Experiment.FEATURE_DENSITY)\n",
        "\n",
        "total_tokens = total_batches * batch_size_tokens\n",
        "n_features = sae.cfg.d_sae\n",
        "\n",
        "density_plotter = FeatureDensityPlotter(n_features, total_tokens)\n",
        "\n",
        "for k in tqdm(range(total_batches)):\n",
        "    # Get a batch of tokens from the dataset\n",
        "    tokens = activation_store.get_batch_tokens()  # [N_BATCH, N_CONTEXT]\n",
        "    all_histogram_tokens.append(tokens)\n",
        "\n",
        "    # Run the model and store the activations\n",
        "    _, cache = base_model.run_with_cache(tokens, stop_at_layer=layer_num + 1, \\\n",
        "                                         names_filter=[sae_id])  # [N_BATCH, N_CONTEXT, D_MODEL]\n",
        "\n",
        "    # Get the activations from the cache and convert to float32 for more accurate density computation\n",
        "    activations_original = cache[sae_id].flatten(0, 1).float() # [N_BATCH, N_CONTEXT, D_SAE]\n",
        "    # activations_filtered = filter_activations(activations_original)\n",
        "\n",
        "    # Encode the activations with the SAE\n",
        "    feature_activations = sae.encode_standard(activations_original) # the result of the encode method of the sae on the \"sae_id\" activations (a specific activation tensor of the LLM)\n",
        "    feature_activations = feature_activations.to('cpu')\n",
        "\n",
        "    # Update the density histogram data\n",
        "    density_plotter.update(feature_activations)\n",
        "\n",
        "    # Explicitly free up memory by deleting the cache and emptying the CUDA cache\n",
        "    del cache\n",
        "    del activations_original\n",
        "    del feature_activations\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "set_tokens_sample(Experiment.FEATURE_DENSITY, torch.cat(all_histogram_tokens))  # [TOTAL_BATCHES * N_BATCH, N_CONTEXT]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uokP6-AwbSG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "e566aa2e-eb52-479f-eb3c-7ff3e055c895"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"96dd6ff3-9660-46be-95a0-302adc9e13b4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"96dd6ff3-9660-46be-95a0-302adc9e13b4\")) {                    Plotly.newPlot(                        \"96dd6ff3-9660-46be-95a0-302adc9e13b4\",                        [{\"width\":0.0984163324534893,\"x\":[-10.0,-9.901584,-9.803167,-9.704751,-9.606335,-9.507918,-9.409502,-9.311086,-9.212669,-9.114253,-9.015837,-8.91742,-8.819004,-8.720588,-8.622171,-8.523755,-8.425339,-8.326922,-8.228506,-8.13009,-8.031673,-7.933257,-7.834841,-7.7364244,-7.638008,-7.539592,-7.4411755,-7.342759,-7.244343,-7.1459265,-7.04751,-6.949094,-6.8506775,-6.752261,-6.653845,-6.5554285,-6.457012,-6.358596,-6.2601795,-6.161763,-6.063347,-5.9649305,-5.866514,-5.768098,-5.6696815,-5.571265,-5.472849,-5.3744326,-5.276016,-5.1776,-5.079183,-4.980767,-4.8823504,-4.783934,-4.685518,-4.5871015,-4.488685,-4.390269,-4.2918525,-4.193436,-4.09502,-3.9966035,-3.8981872,-3.7997708,-3.7013545,-3.6029382,-3.5045218,-3.4061055,-3.3076892,-3.2092729,-3.1108565,-3.0124402,-2.9140239,-2.8156075,-2.7171912,-2.618775,-2.5203586,-2.4219422,-2.323526,-2.2251096,-2.1266932,-2.028277,-1.9298607,-1.8314444,-1.733028,-1.6346117,-1.5361954,-1.4377791,-1.3393627,-1.2409464,-1.1425301,-1.0441138,-0.94569737,-0.84728104,-0.7488647,-0.6504484,-0.55203205,-0.45361573,-0.3551994,-0.25678307],\"y\":[4777.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3056.0,0.0,0.0,2416.0,0.0,1959.0,1807.0,1530.0,1447.0,2602.0,2232.0,2007.0,2634.0,3711.0,3012.0,3042.0,3255.0,3207.0,3160.0,2925.0,2639.0,2682.0,2345.0,2120.0,2175.0,1349.0,1067.0,735.0,551.0,362.0,257.0,158.0,126.0,61.0,41.0,19.0,21.0,14.0,12.0,11.0,7.0,1.0,2.0,0.0,1.0,0.0,0.0,1.0],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis\":{\"title\":{\"text\":\"Density\"},\"range\":[0,7422.0]},\"title\":{\"text\":\"SAE Features Density histogram (Dead features density: 4.78e+03)\"},\"xaxis\":{\"title\":{\"text\":\"Log10 of Density\"}},\"bargap\":0.2,\"bargroupgap\":0.1,\"annotations\":[{\"bgcolor\":\"white\",\"bordercolor\":\"black\",\"borderwidth\":1,\"font\":{\"color\":\"red\",\"size\":12},\"showarrow\":false,\"text\":\"Dead features density: 4.78e+03\",\"x\":0.95,\"xref\":\"paper\",\"y\":0.95,\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('96dd6ff3-9660-46be-95a0-302adc9e13b4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "density_plotter.plot(y_scalar=2, y_scale_bin=-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfD3GAfmzzey"
      },
      "outputs": [],
      "source": [
        "# Save the computed feature densities\n",
        "base_feature_densities = density_plotter.feature_densities\n",
        "\n",
        "# Choose saving names consistent with saetuning/get_scores.py\n",
        "saving_name_base = BASE_MODEL if \"/\" not in BASE_MODEL else BASE_MODEL.split(\"/\")[-1]\n",
        "saving_name_ft = FINETUNE_MODEL if \"/\" not in FINETUNE_MODEL else FINETUNE_MODEL.split(\"/\")[-1]\n",
        "saving_name_ds = DATASET_NAME if \"/\" not in DATASET_NAME else DATASET_NAME.split(\"/\")[-1]\n",
        "\n",
        "base_feature_densities_fname = f'Feature_densities_{saving_name_base}_on_{saving_name_ds}.pt'\n",
        "\n",
        "if IN_COLAB:\n",
        "    saving_path = f'./{base_feature_densities_fname}'\n",
        "else:\n",
        "    from saetuning.utils import get_env_var\n",
        "    _, datapath = get_env_var()\n",
        "\n",
        "    saving_path = datapath / base_feature_densities_fname\n",
        "\n",
        "torch.save(base_feature_densities, saving_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2nk6fv5VN4I"
      },
      "outputs": [],
      "source": [
        "del base_model, activation_store\n",
        "clear_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAZhdorjaYqc"
      },
      "source": [
        "### Task 4.2 FineTuned case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "009a42fa30404a5e9353db4751b7345e",
            "3fc8cebf7b9e4d318a7d8a1ef7334d9f",
            "fb3ae97a1b8e4234b5f3bb9619d7e9cd",
            "587de753df1547c08b4a64ebed879869",
            "b4f486d6a6df4f0da48b1e26172ac4bd",
            "5725aa1113e54d1280eb60edde89d971",
            "38622459fff6412c8465a8abc19c83aa",
            "2acc6f6cb4c64bb3a2535ed6473ece00",
            "5f7730469d5b45ddb6e25094512b0bac",
            "eda52505bde342b4afd24ce56b54216d",
            "0c75557c808548a3a78549cfde182a33"
          ]
        },
        "id": "cfVBH05TaYqd",
        "outputId": "479a3906-df53-4d32-b10f-81c5e8536001"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "009a42fa30404a5e9353db4751b7345e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
            "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model mistral-7b into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "# Load the finetune model and its tokenizer\n",
        "finetune_tokenizer, finetune_model = load_hf_model(FINETUNE_PATH if FINETUNE_PATH is not None else FINETUNE_MODEL,\n",
        "                                                   device=device, dtype=torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2ZpTRiYA-6D"
      },
      "outputs": [],
      "source": [
        "# import the required libraries\n",
        "from sae_lens import SAE\n",
        "\n",
        "sae_id = f'blocks.{layer_num}.hook_resid_{hook_part}' # Gemma is post,\n",
        "\n",
        "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
        "                            release = RELEASE,\n",
        "                            sae_id = sae_id,\n",
        "                            device = device\n",
        ")\n",
        "cfg_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT_zSnb7aYqd"
      },
      "source": [
        "#### 4.2.1 L0 loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBHR-a5FaYqd",
        "outputId": "986bb62c-9525-42ef-f205-9b0ec9f9f3f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [00:11<00:00,  4.50it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "all_L0 = []\n",
        "\n",
        "total_batches = get_batch_size(Experiment.L0_LOSS)\n",
        "all_tokens_L0 = get_tokens_sample(Experiment.L0_LOSS)\n",
        "\n",
        "for k in tqdm(range(total_batches)):\n",
        "    # Use the same sample to calculate the L0 loss.\n",
        "    # Calculate the start and end indices for the current batch\n",
        "    start_idx = k * batch_size_prompts\n",
        "    end_idx = (k + 1) * batch_size_prompts\n",
        "\n",
        "    # Get the corresponding batch of tokens from all_tokens\n",
        "    tokens = all_tokens_L0[start_idx:end_idx]  # [N_BATCH, N_CONTEXT]\n",
        "\n",
        "    # Run the model and store the activations\n",
        "    _, cache = finetune_model.run_with_cache(tokens, stop_at_layer=layer_num + 1, \\\n",
        "                                         names_filter=[sae_id])  # [N_BATCH, N_CONTEXT, D_MODEL]\n",
        "\n",
        "    # Get the activations from the cache at the sae_id\n",
        "    activations_original = cache[sae_id]\n",
        "    # activations_filtered = filter_activations(activations_original)\n",
        "\n",
        "    # Encode the activations with the SAE\n",
        "    feature_activations = sae.encode_standard(activations_original) # the result of the encode method of the sae on the \"sae_id\" activations (a specific activation tensor of the LLM)\n",
        "    # feature_activations.to('cpu')\n",
        "\n",
        "    # Store the encoded activations\n",
        "    all_L0.append(L0_loss(feature_activations))\n",
        "\n",
        "    # Explicitly free up memory by deleting the cache and emptying the CUDA cache\n",
        "    del cache\n",
        "    del activations_original\n",
        "    del feature_activations\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1-JljccaYqd",
        "outputId": "ff181b33-9b32-4057-ff4e-b9cc79d99abb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(91.9437)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "torch.tensor(all_L0).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK26blEThFhx"
      },
      "outputs": [],
      "source": [
        "clear_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG8fAQpuaYqd"
      },
      "source": [
        "#### 4.2.2 Substitution Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMMYKoT7aYqd",
        "outputId": "7b40627a-063b-4cdb-889e-5a4b51a5789a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:41<00:00,  1.67s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "sae_reconstruction_metric = R2Score().to(device)\n",
        "\n",
        "all_SL_clean = []\n",
        "all_SL_reconstructed = []\n",
        "\n",
        "total_batches = get_batch_size(Experiment.SUBSTITUTION_LOSS)\n",
        "all_tokens_SL = get_tokens_sample(Experiment.SUBSTITUTION_LOSS)\n",
        "\n",
        "for k in tqdm(range(total_batches)):\n",
        "    # Use the same sample to calculate the losses.\n",
        "    # Calculate the start and end indices for the current batch\n",
        "    start_idx = k * batch_size_prompts\n",
        "    end_idx = (k + 1) * batch_size_prompts\n",
        "\n",
        "    # Get the corresponding batch of tokens from all_tokens\n",
        "    tokens = all_tokens_SL[start_idx:end_idx]  # [N_BATCH, N_CONTEXT]\n",
        "\n",
        "    # Store loss\n",
        "    clean_loss, reconstructed_loss = get_substitution_loss(tokens, finetune_model, sae, sae_id, sae_reconstruction_metric)\n",
        "    all_SL_clean.append(clean_loss)\n",
        "    all_SL_reconstructed.append(reconstructed_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtXPCQafaYqd",
        "outputId": "1014d4df-6455-4b5f-c4bc-120c08bfbb92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean vs substitution loss:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.935546875, 3.013671875)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "print('Clean vs substitution loss:')\n",
        "torch.tensor(all_SL_clean).mean().item(), torch.tensor(all_SL_reconstructed).mean().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVI_D4W_G16J",
        "outputId": "2fb1d0a5-4694-4b13-acea-0993e7c2ef54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Varience explained by SAE: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6007424592971802"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "print('Varience explained by SAE: ')\n",
        "sae_reconstruction_metric.compute().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JjmtOZpaYqd",
        "outputId": "f01fa715-7e88-442e-9372-7be257aa7cae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.sort(\n",
              "values=tensor([0.6885, 1.6035, 2.0840, 2.4258, 2.5215, 2.5312, 2.5898, 2.6113, 2.6250,\n",
              "        2.7148, 3.0801, 3.0938, 3.1211, 3.2070, 3.3574, 3.4609, 3.5410, 3.6094,\n",
              "        3.6133, 3.7832, 3.7949, 3.8086, 3.8203, 3.8262, 3.8301],\n",
              "       dtype=torch.float16),\n",
              "indices=tensor([12, 11, 20, 19,  0, 24,  6, 23, 10,  8, 22, 13, 21, 18,  4, 15, 16,  3,\n",
              "        14,  9,  5,  2, 17,  1,  7]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "loss_reconstructed_tensor = torch.tensor(all_SL_reconstructed)\n",
        "loss_reconstructed_tensor.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77SOQqGUGDgS",
        "outputId": "4433f596-c853-41bf-e70b-f1918e13cc63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered substitution loss = 3.013671875\n"
          ]
        }
      ],
      "source": [
        "# Filter out NaN values (if there are any)\n",
        "filtered_loss_reconstructed = loss_reconstructed_tensor[~torch.isinf(loss_reconstructed_tensor)]\n",
        "print(f'Filtered substitution loss = {filtered_loss_reconstructed.mean().item()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQfS5sF1IkDL"
      },
      "source": [
        "#### 4.2.3 Feature activations histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17LetYS7Ucp6",
        "outputId": "326ed2db-d173-4a56-aac6-d8e759c41197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:11<00:00,  2.18it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "all_feature_acts = []\n",
        "\n",
        "total_batches = get_batch_size(Experiment.FEATURE_ACTS)\n",
        "all_histogram_tokens = get_tokens_sample(Experiment.FEATURE_ACTS)\n",
        "\n",
        "for k in tqdm(range(total_batches)):\n",
        "    # Use the same sample to calculate the histogram\n",
        "    # Calculate the start and end indices for the current batch\n",
        "    start_idx = k * batch_size_prompts\n",
        "    end_idx = (k + 1) * batch_size_prompts\n",
        "\n",
        "    # Get the corresponding batch of tokens from all_tokens\n",
        "    tokens = all_histogram_tokens[start_idx:end_idx]  # [N_BATCH, N_CONTEXT]\n",
        "\n",
        "    # Run the model and store the activations\n",
        "    _, cache = finetune_model.run_with_cache(tokens, stop_at_layer=layer_num + 1, \\\n",
        "                                         names_filter=[sae_id])  # [N_BATCH, N_CONTEXT, D_MODEL]\n",
        "\n",
        "    # Get the activations from the cache at the sae_id\n",
        "    activations_original = cache[sae_id]\n",
        "    # activations_filtered = filter_activations(activations_original)\n",
        "\n",
        "    # Encode the activations with the SAE\n",
        "    feature_activations = sae.encode_standard(activations_original) # the result of the encode method of the sae on the \"sae_id\" activations (a specific activation tensor of the LLM)\n",
        "    feature_activations = feature_activations.to('cpu')\n",
        "\n",
        "    # Store the encoded activations\n",
        "    all_feature_acts.append(feature_activations)\n",
        "\n",
        "    # Explicitly free up memory by deleting the cache and emptying the CUDA cache\n",
        "    del cache\n",
        "    del activations_original\n",
        "    del feature_activations\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "sMVZ8NelUcp6",
        "outputId": "a9b3014a-f17a-408d-d4c0-30c18a9e15dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6226c4f7-4ba2-458c-b474-523af1e2fa1c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6226c4f7-4ba2-458c-b474-523af1e2fa1c\")) {                    Plotly.newPlot(                        \"6226c4f7-4ba2-458c-b474-523af1e2fa1c\",                        [{\"width\":0.1182956612110138,\"x\":[-10.0,-9.881704,-9.763409,-9.645113,-9.526817,-9.408522,-9.290226,-9.17193,-9.053635,-8.935339,-8.817043,-8.698748,-8.580452,-8.462156,-8.343861,-8.225565,-8.107269,-7.9889736,-7.870678,-7.7523823,-7.6340866,-7.515791,-7.3974953,-7.2791996,-7.160904,-7.0426083,-6.9243126,-6.806017,-6.6877213,-6.5694256,-6.45113,-6.3328342,-6.2145386,-6.0962434,-5.9779477,-5.859652,-5.7413564,-5.6230607,-5.504765,-5.3864694,-5.2681737,-5.149878,-5.0315824,-4.9132867,-4.794991,-4.6766953,-4.5583997,-4.440104,-4.3218083,-4.2035127,-4.085217,-3.9669213,-3.8486257,-3.73033,-3.6120343,-3.4937387,-3.375443,-3.2571473,-3.1388516,-3.020556,-2.9022603,-2.7839646,-2.665669,-2.5473733,-2.4290776,-2.310782,-2.1924863,-2.0741906,-1.9558951,-1.8375994,-1.7193037,-1.601008,-1.4827124,-1.3644167,-1.246121,-1.1278254,-1.0095298,-0.8912341,-0.77293843,-0.65464276,-0.53634715,-0.41805145,-0.2997558,-0.18146014,-0.06316447,0.05513119,0.17342685,0.2917225,0.41001818,0.5283138,0.6466095,0.76490515,0.8832008,1.0014964,1.1197921,1.2380878,1.3563834,1.4746791,1.5929748,1.7112705],\"y\":[100663300.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,2.0,5.0,3.0,3.0,5.0,8.0,9.0,9.0,6.0,9.0,16.0,31.0,38.0,44.0,61.0,76.0,83.0,136.0,162.0,227.0,331.0,408.0,558.0,733.0,927.0,1165.0,1535.0,2069.0,2590.0,3468.0,4464.0,5778.0,7607.0,9499.0,12137.0,15548.0,19198.0,23514.0,28736.0,34731.0,41189.0,46314.0,54602.0,65176.0,78821.0,94086.0,113465.0,134539.0,156307.0,178703.0,197286.0,213639.0,223108.0,223381.0,211866.0,189017.0,155291.0,118139.0,81167.0,52454.0,32271.0,20093.0,11276.0,5340.0,1511.0,124.0,308.0],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis\":{\"title\":{\"text\":\"Density\"},\"range\":[0,335071.5]},\"title\":{\"text\":\"SAE Features activations histogram (First bin value: 1.01e+08)\"},\"xaxis\":{\"title\":{\"text\":\"Log10 of activations\"}},\"bargap\":0.2,\"bargroupgap\":0.1,\"annotations\":[{\"bgcolor\":\"white\",\"bordercolor\":\"black\",\"borderwidth\":1,\"font\":{\"color\":\"red\",\"size\":12},\"showarrow\":false,\"text\":\"First bin value: 1.01e+08\",\"x\":0.95,\"xref\":\"paper\",\"y\":0.95,\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6226c4f7-4ba2-458c-b474-523af1e2fa1c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "all_feature_acts = torch.cat(all_feature_acts)\n",
        "plot_log10_hist(all_feature_acts, 'activations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmvgyCgWwbSI"
      },
      "source": [
        "#### 4.2.4 Feature density histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbD4e4vDwbSI",
        "outputId": "a7d3ea5a-d912-43b3-e920-7c4dd23d926b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [00:30<00:00,  1.65it/s]\n"
          ]
        }
      ],
      "source": [
        "all_histogram_tokens = get_tokens_sample(Experiment.FEATURE_DENSITY)\n",
        "total_batches = get_batch_size(Experiment.FEATURE_DENSITY)\n",
        "\n",
        "total_tokens = total_batches * batch_size_tokens\n",
        "n_features = sae.cfg.d_sae\n",
        "\n",
        "density_plotter = FeatureDensityPlotter(n_features, total_tokens)\n",
        "\n",
        "for k in tqdm(range(total_batches)):\n",
        "    # Use the same sample to calculate the histogram\n",
        "    # Calculate the start and end indices for the current batch\n",
        "    start_idx = k * batch_size_prompts\n",
        "    end_idx = (k + 1) * batch_size_prompts\n",
        "\n",
        "    # Get the corresponding batch of tokens from all_tokens\n",
        "    tokens = all_histogram_tokens[start_idx:end_idx]  # [N_BATCH, N_CONTEXT]\n",
        "\n",
        "    # Run the model and store the activations\n",
        "    _, cache = finetune_model.run_with_cache(tokens, stop_at_layer=layer_num + 1, \\\n",
        "                                             names_filter=[sae_id])  # [N_BATCH, N_CONTEXT, D_MODEL]\n",
        "\n",
        "    # Get the activations from the cache at the sae_id\n",
        "    activations_original = cache[sae_id].flatten(0, 1).float()\n",
        "    # activations_filtered = filter_activations(activations_original)\n",
        "\n",
        "    # Encode the activations with the SAE\n",
        "    feature_activations = sae.encode_standard(activations_original) # the result of the encode method of the sae on the \"sae_id\" activations (a specific activation tensor of the LLM)\n",
        "    feature_activations = feature_activations.to('cpu')\n",
        "\n",
        "    # Update the density histogram data\n",
        "    density_plotter.update(feature_activations)\n",
        "\n",
        "    # Explicitly free up memory by deleting the cache and emptying the CUDA cache\n",
        "    del cache\n",
        "    del activations_original\n",
        "    del feature_activations\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "leqgFkTKwbSI",
        "outputId": "5330f2a6-7ff2-4629-b114-373f29affd80"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"beb154b7-4606-47c0-bf93-0356574376ff\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"beb154b7-4606-47c0-bf93-0356574376ff\")) {                    Plotly.newPlot(                        \"beb154b7-4606-47c0-bf93-0356574376ff\",                        [{\"width\":0.096699558198452,\"x\":[-10.0,-9.9033,-9.806601,-9.709901,-9.613202,-9.516502,-9.419803,-9.323103,-9.226403,-9.1297035,-9.033005,-8.936305,-8.839605,-8.742906,-8.646206,-8.549506,-8.452806,-8.356108,-8.259408,-8.162708,-8.066009,-7.9693093,-7.8726096,-7.77591,-7.6792107,-7.582511,-7.485811,-7.3891115,-7.2924123,-7.1957126,-7.099013,-7.0023136,-6.905614,-6.808914,-6.712215,-6.615515,-6.5188155,-6.4221163,-6.3254166,-6.228717,-6.132017,-6.035318,-5.938618,-5.8419185,-5.745219,-5.6485195,-5.55182,-5.4551206,-5.358421,-5.261721,-5.1650224,-5.068323,-4.9716234,-4.8749237,-4.778224,-4.6815248,-4.584825,-4.4881253,-4.391426,-4.2947264,-4.1980267,-4.1013274,-4.0046277,-3.907928,-3.8112285,-3.714529,-3.6178293,-3.5211298,-3.4244304,-3.3277307,-3.2310312,-3.1343317,-3.037632,-2.9409325,-2.8442328,-2.7475333,-2.6508338,-2.5541341,-2.4574347,-2.360735,-2.2640355,-2.167336,-2.0706363,-1.9739368,-1.8772372,-1.7805376,-1.6838381,-1.5871385,-1.4904389,-1.3937395,-1.2970399,-1.2003403,-1.1036407,-1.0069411,-0.9102416,-0.813542,-0.7168424,-0.6201429,-0.52344334,-0.42674375],\"y\":[3697.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2736.0,0.0,0.0,2384.0,0.0,1938.0,1712.0,1540.0,1459.0,1338.0,2375.0,2987.0,2594.0,3056.0,3232.0,3082.0,3036.0,3157.0,3215.0,3054.0,2788.0,2745.0,2531.0,2266.0,2432.0,1763.0,1262.0,995.0,672.0,531.0,330.0,217.0,147.0,94.0,53.0,31.0,25.0,19.0,12.0,15.0,6.0,5.0,1.0,2.0,0.0,1.0,1.0],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis\":{\"title\":{\"text\":\"Density\"},\"range\":[0,5545.5]},\"title\":{\"text\":\"SAE Features Density histogram (Dead features density: 3.70e+03)\"},\"xaxis\":{\"title\":{\"text\":\"Log10 of Density\"}},\"bargap\":0.2,\"bargroupgap\":0.1,\"annotations\":[{\"bgcolor\":\"white\",\"bordercolor\":\"black\",\"borderwidth\":1,\"font\":{\"color\":\"red\",\"size\":12},\"showarrow\":false,\"text\":\"Dead features density: 3.70e+03\",\"x\":0.95,\"xref\":\"paper\",\"y\":0.95,\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('beb154b7-4606-47c0-bf93-0356574376ff');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "density_plotter.plot(y_scalar=1.5, y_scale_bin=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lop2WUJWzze3"
      },
      "outputs": [],
      "source": [
        "# Save the computed feature densities\n",
        "finetune_feature_densities = density_plotter.feature_densities\n",
        "\n",
        "# Choose saving names consistent with saetuning/get_scores.py\n",
        "finetune_feature_densities_fname = f'Feature_densities_{saving_name_ft}_on_{saving_name_ds}.pt'\n",
        "\n",
        "if IN_COLAB:\n",
        "    saving_path = f'./{finetune_feature_densities_fname}'\n",
        "else:\n",
        "    from saetuning.utils import get_env_var\n",
        "    _, datapath = get_env_var()\n",
        "\n",
        "    saving_path = datapath / finetune_feature_densities_fname\n",
        "\n",
        "torch.save(finetune_feature_densities, saving_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpGKy6iPwbSI"
      },
      "outputs": [],
      "source": [
        "total_tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYfRit0t5Dj-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee45f96a5b174a75b68c405b6bafb9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d4374a927134e37912e081df0d1c025",
              "IPY_MODEL_3cb9a007321c4894bb7ac46c8f1c35aa",
              "IPY_MODEL_706c40f521824b4ebb2fdf2b45633490"
            ],
            "layout": "IPY_MODEL_159e2699d2bb44f2a9a3cf9c3af780a6"
          }
        },
        "9d4374a927134e37912e081df0d1c025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac153d870cd9471494ebb7bd9699448d",
            "placeholder": "",
            "style": "IPY_MODEL_7763a6df19e3407faf6d300c563cdfa2",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "3cb9a007321c4894bb7ac46c8f1c35aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0692f5a3c17f4940b454f53ae7838bc8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7454f1750351443c84b2c8bd137d0527",
            "value": 2
          }
        },
        "706c40f521824b4ebb2fdf2b45633490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bdccb792aa542a28622c3a7df70b3e5",
            "placeholder": "",
            "style": "IPY_MODEL_515e503c959045f280bee545711ceb0a",
            "value": "2/2[01:01&lt;00:00,28.64s/it]"
          }
        },
        "159e2699d2bb44f2a9a3cf9c3af780a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac153d870cd9471494ebb7bd9699448d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7763a6df19e3407faf6d300c563cdfa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0692f5a3c17f4940b454f53ae7838bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7454f1750351443c84b2c8bd137d0527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bdccb792aa542a28622c3a7df70b3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "515e503c959045f280bee545711ceb0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f565615765d147789c678363e4b9b0dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cd1a88e41f341af90d503bcc5dacabc",
              "IPY_MODEL_a449e385fc0a4c50948aa90407253b57",
              "IPY_MODEL_a51dca60ad0d48f9bb8adb252c664496"
            ],
            "layout": "IPY_MODEL_f86bacf36e12413dba2a34fda650a234"
          }
        },
        "5cd1a88e41f341af90d503bcc5dacabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fd5b206998540979d2796f538839ccd",
            "placeholder": "",
            "style": "IPY_MODEL_216670d6bcd24e03bdb25026dd4dbdef",
            "value": "Resolvingdatafiles:100%"
          }
        },
        "a449e385fc0a4c50948aa90407253b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b266cab1b4b7412fabb1dc8ee2b0461f",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d223c86303a64cb4a495d4623802c8be",
            "value": 30
          }
        },
        "a51dca60ad0d48f9bb8adb252c664496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830c8e2538d0443bbf80ad25b02a6069",
            "placeholder": "",
            "style": "IPY_MODEL_b52109a7755a46689ef1479915974a92",
            "value": "30/30[00:00&lt;00:00,9.28it/s]"
          }
        },
        "f86bacf36e12413dba2a34fda650a234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fd5b206998540979d2796f538839ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216670d6bcd24e03bdb25026dd4dbdef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b266cab1b4b7412fabb1dc8ee2b0461f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d223c86303a64cb4a495d4623802c8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "830c8e2538d0443bbf80ad25b02a6069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b52109a7755a46689ef1479915974a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "009a42fa30404a5e9353db4751b7345e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fc8cebf7b9e4d318a7d8a1ef7334d9f",
              "IPY_MODEL_fb3ae97a1b8e4234b5f3bb9619d7e9cd",
              "IPY_MODEL_587de753df1547c08b4a64ebed879869"
            ],
            "layout": "IPY_MODEL_b4f486d6a6df4f0da48b1e26172ac4bd"
          }
        },
        "3fc8cebf7b9e4d318a7d8a1ef7334d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5725aa1113e54d1280eb60edde89d971",
            "placeholder": "",
            "style": "IPY_MODEL_38622459fff6412c8465a8abc19c83aa",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "fb3ae97a1b8e4234b5f3bb9619d7e9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2acc6f6cb4c64bb3a2535ed6473ece00",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f7730469d5b45ddb6e25094512b0bac",
            "value": 6
          }
        },
        "587de753df1547c08b4a64ebed879869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda52505bde342b4afd24ce56b54216d",
            "placeholder": "",
            "style": "IPY_MODEL_0c75557c808548a3a78549cfde182a33",
            "value": "6/6[00:03&lt;00:00,1.92it/s]"
          }
        },
        "b4f486d6a6df4f0da48b1e26172ac4bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5725aa1113e54d1280eb60edde89d971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38622459fff6412c8465a8abc19c83aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2acc6f6cb4c64bb3a2535ed6473ece00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f7730469d5b45ddb6e25094512b0bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eda52505bde342b4afd24ce56b54216d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c75557c808548a3a78549cfde182a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}